09/10/2019 02:24:31 AM =================================================
09/10/2019 02:24:31 AM ChemMLWrapper 0.6.0 (August 2019)
09/10/2019 02:24:31 AM Mojtaba Haghighatlari (mojtabah@buffalo.edu)
09/10/2019 02:24:31 AM Johannes Hachmann (hachmann@buffalo.edu)
09/10/2019 02:24:31 AM =================================================
09/10/2019 02:24:31 AM Tue Sep 10 02:24:31 2019
09/10/2019 02:24:31 AM 
09/10/2019 02:24:31 AM parsing the input dictionary ...

09/10/2019 02:24:31 AM 1   ID1: read_csv (pandas)
09/10/2019 02:24:31 AM         <<<<<<< receive from:
09/10/2019 02:24:31 AM         nothing to receive!
09/10/2019 02:24:31 AM         >>>>>>> send to:
09/10/2019 02:24:31 AM         ID2
09/10/2019 02:24:31 AM         
09/10/2019 02:24:31 AM 2   ID2: StandardScaler (sklearn)
09/10/2019 02:24:31 AM         method = fit_transform
09/10/2019 02:24:31 AM         <<<<<<< receive from:
09/10/2019 02:24:31 AM         ID1
09/10/2019 02:24:31 AM         >>>>>>> send to:
09/10/2019 02:24:31 AM         ID3
09/10/2019 02:24:31 AM         
09/10/2019 02:24:31 AM 3   ID3: PCA (sklearn)
09/10/2019 02:24:31 AM         method = fit_transform
09/10/2019 02:24:31 AM         <<<<<<< receive from:
09/10/2019 02:24:31 AM         ID2
09/10/2019 02:24:31 AM         >>>>>>> send to:
09/10/2019 02:24:31 AM         ID4
09/10/2019 02:24:31 AM         
09/10/2019 02:24:31 AM 4   ID4: SplitColumns (chemml)
09/10/2019 02:24:31 AM         method = fit
09/10/2019 02:24:31 AM         <<<<<<< receive from:
09/10/2019 02:24:31 AM         ID3
09/10/2019 02:24:31 AM         >>>>>>> send to:
09/10/2019 02:24:31 AM         ID5
09/10/2019 02:24:31 AM         ID5
09/10/2019 02:24:31 AM         
09/10/2019 02:24:31 AM 5   ID5: train_test_split (sklearn)
09/10/2019 02:24:31 AM         <<<<<<< receive from:
09/10/2019 02:24:31 AM         ID4
09/10/2019 02:24:31 AM         ID4
09/10/2019 02:24:31 AM         >>>>>>> send to:
09/10/2019 02:24:31 AM         ID6
09/10/2019 02:24:31 AM         ID6
09/10/2019 02:24:31 AM         ID7
09/10/2019 02:24:31 AM         ID8
09/10/2019 02:24:31 AM         
09/10/2019 02:24:31 AM 6   ID6: LinearRegression (sklearn)
09/10/2019 02:24:31 AM         method = fit
09/10/2019 02:24:31 AM         <<<<<<< receive from:
09/10/2019 02:24:31 AM         ID5
09/10/2019 02:24:31 AM         ID5
09/10/2019 02:24:31 AM         >>>>>>> send to:
09/10/2019 02:24:31 AM         ID7
09/10/2019 02:24:31 AM         
09/10/2019 02:24:31 AM 7   ID7: LinearRegression (sklearn)
09/10/2019 02:24:31 AM         method = predict
09/10/2019 02:24:31 AM         <<<<<<< receive from:
09/10/2019 02:24:31 AM         ID6
09/10/2019 02:24:31 AM         ID5
09/10/2019 02:24:31 AM         >>>>>>> send to:
09/10/2019 02:24:31 AM         ID8
09/10/2019 02:24:31 AM         
09/10/2019 02:24:31 AM 8   ID8: mean_absolute_error (sklearn)
09/10/2019 02:24:31 AM         <<<<<<< receive from:
09/10/2019 02:24:31 AM         ID5
09/10/2019 02:24:31 AM         ID7
09/10/2019 02:24:31 AM         >>>>>>> send to:
09/10/2019 02:24:31 AM         ID9
09/10/2019 02:24:31 AM         
09/10/2019 02:24:31 AM 9   ID9: SaveFile (chemml)
09/10/2019 02:24:31 AM         method = write
09/10/2019 02:24:31 AM         <<<<<<< receive from:
09/10/2019 02:24:31 AM         ID8
09/10/2019 02:24:31 AM         >>>>>>> send to:
09/10/2019 02:24:31 AM         nothing to send!
09/10/2019 02:24:31 AM         
09/10/2019 02:24:31 AM =================================================
09/10/2019 02:24:31 AM * Based on the dependencies, we run nodes in the 
09/10/2019 02:24:31 AM   following order:
09/10/2019 02:24:31 AM   ['ID1']
09/10/2019 02:24:31 AM   ['ID2']
09/10/2019 02:24:31 AM   ['ID3']
09/10/2019 02:24:31 AM   ['ID4']
09/10/2019 02:24:31 AM   ['ID5']
09/10/2019 02:24:31 AM   ['ID6']
09/10/2019 02:24:31 AM   ['ID7']
09/10/2019 02:24:31 AM   ['ID8']
09/10/2019 02:24:31 AM   ['ID9']
09/10/2019 02:24:31 AM * The outputs will be stored in the following 
09/10/2019 02:24:31 AM directory: output/48-4
09/10/2019 02:24:31 AM 

09/10/2019 02:24:31 AM ======= node ID#ID1: (read_csv, pandas)
09/10/2019 02:24:31 AM | run ...

09/10/2019 02:24:31 AM Created new connection <sqlite3.Connection object at 0x7f011c86bab0>
09/10/2019 02:24:31 AM SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1
09/10/2019 02:24:31 AM ()
09/10/2019 02:24:31 AM SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1
09/10/2019 02:24:31 AM ()
09/10/2019 02:24:31 AM Connection <sqlite3.Connection object at 0x7f011c86bab0> checked out from pool
09/10/2019 02:24:31 AM PRAGMA main.table_info("celery_taskmeta")
09/10/2019 02:24:31 AM ()
09/10/2019 02:24:31 AM Col ('cid', 'name', 'type', 'notnull', 'dflt_value', 'pk')
09/10/2019 02:24:31 AM Row (0, 'id', 'INTEGER', 1, None, 1)
09/10/2019 02:24:31 AM Row (1, 'task_id', 'VARCHAR(155)', 0, None, 0)
09/10/2019 02:24:31 AM Row (2, 'status', 'VARCHAR(50)', 0, None, 0)
09/10/2019 02:24:31 AM Row (3, 'result', 'BLOB', 0, None, 0)
09/10/2019 02:24:31 AM Row (4, 'date_done', 'DATETIME', 0, None, 0)
09/10/2019 02:24:31 AM Row (5, 'traceback', 'TEXT', 0, None, 0)
09/10/2019 02:24:31 AM PRAGMA main.table_info("celery_tasksetmeta")
09/10/2019 02:24:31 AM ()
09/10/2019 02:24:31 AM Col ('cid', 'name', 'type', 'notnull', 'dflt_value', 'pk')
09/10/2019 02:24:31 AM Row (0, 'id', 'INTEGER', 1, None, 1)
09/10/2019 02:24:31 AM Row (1, 'taskset_id', 'VARCHAR(155)', 0, None, 0)
09/10/2019 02:24:31 AM Row (2, 'result', 'BLOB', 0, None, 0)
09/10/2019 02:24:31 AM Row (3, 'date_done', 'DATETIME', 0, None, 0)
09/10/2019 02:24:31 AM Connection <sqlite3.Connection object at 0x7f011c86bab0> being returned to pool
09/10/2019 02:24:31 AM Connection <sqlite3.Connection object at 0x7f011c86bab0> rollback-on-return
09/10/2019 02:24:31 AM Closing connection <sqlite3.Connection object at 0x7f011c86bab0>
09/10/2019 02:24:31 AM Created new connection <sqlite3.Connection object at 0x7f00f7812b90>
09/10/2019 02:24:31 AM Connection <sqlite3.Connection object at 0x7f00f7812b90> checked out from pool
09/10/2019 02:24:31 AM BEGIN (implicit)
09/10/2019 02:24:31 AM SELECT celery_taskmeta.id AS celery_taskmeta_id, celery_taskmeta.task_id AS celery_taskmeta_task_id, celery_taskmeta.status AS celery_taskmeta_status, celery_taskmeta.result AS celery_taskmeta_result, celery_taskmeta.date_done AS celery_taskmeta_date_done, celery_taskmeta.traceback AS celery_taskmeta_traceback 
FROM celery_taskmeta 
WHERE celery_taskmeta.task_id = ?
09/10/2019 02:24:31 AM ('24220d25-ca31-4c59-97e0-f3411c8530b7',)
09/10/2019 02:24:31 AM Col ('celery_taskmeta_id', 'celery_taskmeta_task_id', 'celery_taskmeta_status', 'celery_taskmeta_result', 'celery_taskmeta_date_done', 'celery_taskmeta_traceback')
09/10/2019 02:24:31 AM INSERT INTO celery_taskmeta (task_id, status, result, date_done, traceback) VALUES (?, ?, ?, ?, ?)
09/10/2019 02:24:31 AM ('24220d25-ca31-4c59-97e0-f3411c8530b7', 'PENDING', None, '2019-09-10 02:24:31.351313', None)
09/10/2019 02:24:31 AM UPDATE celery_taskmeta SET status=?, result=?, date_done=?, traceback=? WHERE celery_taskmeta.id = ?
09/10/2019 02:24:31 AM ('FAILURE', <memory at 0x7f0116c3e048>, '2019-09-10 02:24:31.357459', 'Traceback (most recent call last):\n  File "/home/sahmed9/.local/share/virtualenvs/server-S9jwYjbZ/lib/python3.7/site-packages/celery/app/trace.py",  ... (2000 characters truncated) ... tReader._setup_parser_source\nFileNotFoundError: [Errno 2] File b\'/home/sahmed9/tmp/Boston.csv\' does not exist: b\'/home/sahmed9/tmp/Boston.csv\'\n', 488)
09/10/2019 02:24:31 AM COMMIT
09/10/2019 02:24:31 AM Connection <sqlite3.Connection object at 0x7f00f7812b90> being returned to pool
09/10/2019 02:24:31 AM Connection <sqlite3.Connection object at 0x7f00f7812b90> rollback-on-return
09/10/2019 02:24:31 AM Closing connection <sqlite3.Connection object at 0x7f00f7812b90>
